\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{mathtools}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{braket}

\geometry{margin=1in}

% Theorem environments
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{prediction}[theorem]{Prediction}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{limitation}[theorem]{Limitation}
\newtheorem{concern}[theorem]{Critical Concern}

% Custom commands
\newcommand{\Fsm}{\textbf{Fsm}}
\newcommand{\Hilbfsm}{\textbf{Hilb}_{\text{fsm}}}
\newcommand{\Hom}{\text{Hom}}
\newcommand{\id}{\text{id}}
\newcommand{\Tr}{\text{Tr}}

% Entropic scaling notation
\newcommand{\InfoCapacity}[1]{I(#1)}
\newcommand{\EntropicScale}[1]{\kappa #1 \log #1}
\newcommand{\TemporalScale}[1]{\tau_0 + \gamma #1 \log #1}

\title{Hierarchical Projection Model of Quantum Measurement:\\Testable Deviations from Standard Theory}
\author{Karol Kowalczyk}
\date{November 9, 2025}

\begin{document}

\maketitle

\begin{abstract}
We propose that quantum measurement can be expressed as hierarchical projection between computational levels in a finite information hierarchy. Each level $n$ corresponds to a Hilbert space with effective information capacity $I(n) = \kappa n \log n$. Measurement is modeled as projection $P_Q: \mathcal{H}_j \to \mathcal{H}_i$ from level $j$ to $i < j$, with collapse operators $C_Q: \mathcal{H}_i \to \mathcal{H}_j$ forming an approximate adjunction $(C_Q \dashv P_Q)$. Extending the \emph{Adjoint Projections on Computational Hierarchies} framework to quantum systems, we show that completely positive trace-preserving (CPTP) maps realize $\varepsilon$-adjunctions with deviations quantified by decoherence parameters. 

The model predicts two testable deviations from standard quantum mechanics: (1) finite measurement delay scaling as $\tau(n) = \tau_0 + \gamma n \log n$ for $n$-qubit systems (entropic scaling replacing quadratic), and (2) small oscillatory corrections to the Born rule from cross-level interference with amplitude $A(n) \propto 1/(n \log n)$. These effects should be observable in mid-scale systems (10--20 qubits) using current ion-trap and superconducting-qubit technology. We provide detailed experimental protocols, derive thermodynamic implications via a modified Landauer bound, and discuss interpretational consequences. The framework offers concrete, falsifiable predictions distinguishing it from standard quantum theory while remaining agnostic about ontological questions.
\end{abstract}

\noindent\textbf{Keywords:} Quantum measurement, computational hierarchy, CPTP maps, Born rule, decoherence, information theory, entropic scaling

\noindent\textbf{Note:} Adjunction in this paper refers to category-theoretic functorial duality $(C_Q \dashv P_Q)$, not Hermitian conjugation $(A^\dagger)$ of operators.

% Note: Entropic scaling I(n) = Îº n log n is used throughout to provide physically realistic computational complexity

\tableofcontents

\newpage

\section{Glossary of Symbols}
\label{sec:glossary}

For ease of reference, we collect the main notation:

\begin{center}
\begin{tabular}{ll}
\hline
\textbf{Symbol} & \textbf{Meaning} \\
\hline
$\mathcal{H}_n$ & Hilbert space at level $n$ with effective capacity $I(n) = \kappa n \log n$ \\
$I(n)$ & Information capacity at level $n$: $\kappa n \log n$ bits \\
$\rho$ & Density operator (density matrix) \\
$U_n$ & Unitary operator on $\mathcal{H}_n$ \\
$P_Q$ & Quantum projection operator (CPTP map) \\
$C_Q$ & Quantum collapse operator (embedding) \\
$\eta_Q$ & Unit of quantum adjunction $\id \Rightarrow C_Q \circ P_Q$ \\
$\varepsilon_Q$ & Counit of quantum adjunction $P_Q \circ C_Q \Rightarrow \id$ \\
$\Tr_E$ & Partial trace over environment $E$ \\
$S(\rho)$ & Von Neumann entropy: $-\Tr(\rho \log \rho)$ \\
$D(\rho, \sigma)$ & Trace distance: $\frac{1}{2}\Tr|\rho - \sigma|$ \\
$\tau(n)$ & Measurement delay time: $\tau_0 + \gamma n \log n$ \\
$n$ & Hierarchy level (number of qubits) \\
$\kappa$ & Entropic scaling constant \\
$\gamma$ & Temporal scaling factor \\
$\varepsilon$ & Approximation error in adjunction \\
$\Hilbfsm$ & Category of finite-dimensional Hilbert spaces \\
\hline
\end{tabular}
\end{center}

\section{Introduction}

\subsection{The measurement problem and information-theoretic approaches}

Quantum mechanics predicts measurement outcomes probabilistically via the Born rule but treats wavefunction collapse as instantaneous and non-dynamical. This ``measurement problem'' has generated numerous interpretations---Copenhagen, Many-Worlds, objective collapse models---each addressing the issue philosophically without providing testable deviations from standard predictions.

Recent information-theoretic approaches (QBism, relational QM, constructor theory) reframe measurement as knowledge update or agent-relative state assignment. While conceptually appealing, these frameworks typically don't predict new measurable phenomena. We take a different approach: treating measurement as \textbf{finite computation} within an explicitly constructed hierarchy of information-processing levels with entropic scaling.

\subsection{Hierarchical computation and quantum systems}

% Scaling derived from entropic computational complexity; replaces arbitrary quadratic form
The \emph{Adjoint Projections on Computational Hierarchies} framework \cite{kowalczyk2025} formalizes nested computational levels $\{M_n\}$ with effective information capacity $I(n) = \kappa n \log n$ bits. Projection operators $P_{j\to i}$ compress information from level $j$ to level $i < j$, while collapse operators $C_{i\to j}$ reconstruct higher-level structure. The pair $(C, P)$ forms an adjunction satisfying category-theoretic identities.

\textbf{Key insight:} Mapping this structure to quantum systems by identifying $n$ with the number of qubits, we interpret measurement as projection between hierarchy levels. Crucially, we assume projection requires \textbf{finite time} proportional to the entropic computational complexity of processing $I(n) = \kappa n \log n$ bits of information.

\subsection{Scope and non-goals}

This framework provides a \emph{formal mathematical structure} for quantum measurement without committing to specific ontological interpretations. We do not claim that:
\begin{itemize}
\item Computational levels are the fundamental constituents of reality
\item Measurement is "really" a computational process
\item Standard quantum mechanics is incorrect
\end{itemize}

Rather, we show that \emph{if} measurement involves hierarchical information processing with entropic scaling, then specific testable predictions follow. The framework is agnostic about whether this structure reflects physical reality or is merely a useful mathematical model. Physical validation---or falsification---will determine its empirical status.

\subsection{Main predictions}

Two testable consequences follow from entropic scaling:

\begin{enumerate}
\item \textbf{Projection delay:} Measurement time $\tau$ scales as $\tau(n) = \tau_0 + \gamma n \log n$ (entropically with qubit number), contrasting with standard QM ($\tau = 0$, instantaneous) and simple decoherence theory ($\tau$ independent of $n$ or linear in $n$).

\item \textbf{Born-rule oscillations:} Cross-level interference introduces small periodic corrections: $P(\text{outcome}) = |\alpha|^2 + A(n)\cdot\sin(2\pi\tau/T)$ where $A(n) \propto 1/(n \log n)$ and period $T$ depends on level separation.
\end{enumerate}

Both predictions are testable with current technology in 10--20 qubit systems, with the entropic scaling providing more realistic timescales than quadratic scaling.

\subsection{Critical concerns and limitations}

Before proceeding, we must acknowledge fundamental concerns with this approach:

\begin{concern}[Physical justification]
\label{concern:physical}
\textbf{Why should quantum measurement involve computational hierarchy?} Decoherence theory successfully explains measurement outcomes without invoking computational levels. The connection between quantum projection and entropic complexity appears forced rather than derived from fundamental principles. We have no mechanism explaining why nature would implement hierarchical projection.
\end{concern}

\begin{concern}[Entropic scaling assumption]
\label{concern:scaling}
The $\tau(n) = \tau_0 + \gamma n \log n$ prediction assumes entropic information processing complexity. While more realistic than exponential scaling, this specific form remains an empirical hypothesis to be tested rather than derived from first principles.
\end{concern}

\begin{concern}[Decoherence conflict]
\label{concern:decoherence}
Standard decoherence theory already explains measurement without hierarchical structure. Adding computational levels seems redundant unless experiments confirm the predicted $n \log n$ scaling.
\end{concern}

\subsection{Why pursue this approach?}

Despite these concerns:
\begin{enumerate}
\item \textbf{Falsifiability:} The predictions are concrete and testable with current technology. Falsification would be scientifically valuable, constraining how measurement relates to computation.

\item \textbf{Alternative perspective:} Even if ultimately wrong, exploring computational approaches with entropic scaling may inspire new experimental techniques or theoretical insights.

\item \textbf{Explicit limitations:} By clearly stating weaknesses upfront, we enable informed critique and avoid misleading claims.
\end{enumerate}

The framework should be viewed as \emph{highly speculative} but \emph{rigorously falsifiable}.

\subsection{Relationship to prior work}

Our approach differs from:
\begin{itemize}
\item \textbf{Decoherence theory} \cite{zurek2003,joos2003,schlosshauer2007}: We predict $\tau \propto n \log n$, not $\tau \sim$ constant or $\tau \propto n$
\item \textbf{Objective collapse} \cite{penrose1996}: We derive $\tau$ from entropic information processing, not spontaneous localization
\item \textbf{Quantum Darwinism} \cite{zurek2009}: We focus on single-system measurement, not environmental redundancy
\item \textbf{Constructor theory} \cite{deutsch2015}: We provide computational implementation with entropic complexity bounds
\item \textbf{Categorical quantum mechanics} \cite{abramsky2004}: We use adjunctions without dagger compact structure; our focus is computational cost not compositionality
\end{itemize}

\textbf{Novel aspect:} Connecting measurement dynamics to entropic computational complexity via explicit hierarchy levels and adjunction structure---though physical motivation remains unclear (Concern~\ref{concern:physical}).

\subsection{Paper organization}

Section~\ref{sec:framework} reviews the hierarchical framework with entropic scaling. Section~\ref{sec:cptp} develops CPTP maps as approximate adjunctions. Section~\ref{sec:delay} derives the $\tau \propto n \log n$ scaling. Section~\ref{sec:born} analyzes Born-rule corrections. Section~\ref{sec:experiments} presents experimental protocols. Section~\ref{sec:thermo} discusses thermodynamics. Section~\ref{sec:interpretation} addresses interpretation. Section~\ref{sec:falsification} states limitations and falsifiability criteria. Section~\ref{sec:conclusion} concludes.

\section{Framework Overview: Computational Hierarchies and Quantum Systems}
\label{sec:framework}

\subsection{Review: Finite computational machines with entropic scaling}

From \cite{kowalczyk2025}, a computational hierarchy $\{M_n\}_{n\in\mathbb{N}}$ consists of finite machines $M_n = (S_n, f_n, \pi_n)$ where:
\begin{itemize}
\item Effective information capacity $I(n) = \kappa n \log n$ bits
\item State space $S_n$ has effective distinguishable states scaling as $\exp(I(n))$
\item Transition function $f_n: S_n \to S_n$ is deterministic
\item Probability distribution $\pi_n: S_n \to [0,1]$ satisfies $\sum_s \pi_n(s) = 1$
\end{itemize}

The entropic scaling $I(n) = \kappa n \log n$ provides super-linear but sub-exponential growth, avoiding unrealistic exponential resource requirements while maintaining computational universality.

Levels connect via:
\begin{itemize}
\item \textbf{Embeddings} $\sigma_{i\to j}: S_i \hookrightarrow S_j$ (injective, structure-preserving)
\item \textbf{Projections} $P_{j\to i}: S_j \to S_i$ (surjective, entropy-minimizing)
\item \textbf{Collapses} $C_{i\to j}: S_i \to S_j$ (injective, left adjoint to $P$)
\end{itemize}

The pair $(C, P)$ forms a category-theoretic adjunction with unit $\eta: \id \Rightarrow C \circ P$ and counit $\varepsilon: P \circ C \Rightarrow \id$.

\subsection{Quantum analog: Hilbert space hierarchy with entropic capacity}

\begin{definition}[Quantum hierarchy with entropic scaling]
A quantum hierarchy $\{\mathcal{H}_n\}_{n\in\mathbb{N}}$ consists of finite-dimensional Hilbert spaces with effective information capacity $I(n) = \kappa n \log n$, equipped with:
\begin{itemize}
\item Density operators $\rho_n$ on $\mathcal{H}_n$
\item Unitary evolution $U_n: \mathcal{H}_n \to \mathcal{H}_n$
\item CPTP maps $\mathcal{E}_n: \mathcal{L}(\mathcal{H}_n) \to \mathcal{L}(\mathcal{H}_n)$ on the space of linear operators
\end{itemize}
\end{definition}

For $n$-qubit systems, the effective information capacity $I(n) = \kappa n \log n$ corresponds to level $n$ in the computational hierarchy.

\subsection{Category $\Hilbfsm$: Morphisms in finite quantum hierarchy}

\begin{definition}[Category $\Hilbfsm$]
The category $\Hilbfsm$ has:
\begin{itemize}
\item \textbf{Objects:} Finite-dimensional Hilbert spaces $\mathcal{H}_n$ with effective capacity $I(n) = \kappa n \log n$
\item \textbf{Morphisms:} CPTP maps $\mathcal{E}: \mathcal{L}(\mathcal{H}_i) \to \mathcal{L}(\mathcal{H}_j)$ that preserve density operator evolution
\item \textbf{Composition:} Standard composition of CPTP maps
\item \textbf{Identities:} $\id_{\mathcal{H}_n}$ is the identity CPTP map
\end{itemize}
\end{definition}

This parallels the category $\Fsm$ for classical computational hierarchies, with CPTP maps replacing transition-preserving functions.

\section{Measurement Delay: Entropic Scaling}
\label{sec:delay}

\subsection{Core hypothesis: Measurement requires computational time}

\begin{prediction}[Entropic measurement delay]
\label{pred:delay}
Quantum measurement from level $j$ to level $i < j$ requires time:
\begin{equation}
\tau(n) = \tau_0 + \gamma n \log n
\end{equation}
where $n = j - i$ is the level separation, $\tau_0$ is baseline processing time, and $\gamma$ is the entropic temporal scaling factor.
\end{prediction}

\textbf{Justification:} Processing information at level $n$ requires handling $I(n) = \kappa n \log n$ bits. The temporal complexity follows entropic scaling, consistent with information-theoretic bounds on computation.

\subsection{Comparison with existing theories}

\begin{center}
\begin{tabular}{lcc}
\hline
\textbf{Theory} & \textbf{Measurement time} & \textbf{Scaling with $n$} \\
\hline
Standard QM & $\tau = 0$ & None \\
Decoherence & $\tau \sim 1/\gamma_{\text{env}}$ & Constant or $\propto n$ \\
Objective collapse & $\tau \sim \hbar/E_{\text{grav}}$ & $\propto m \propto n$ \\
\textbf{This work} & $\tau = \tau_0 + \gamma n \log n$ & \textbf{Entropic} \\
\hline
\end{tabular}
\end{center}

The entropic scaling is unique to our framework and provides a concrete experimental test.

\section{Born Rule Corrections: Cross-Level Interference}
\label{sec:born}

\subsection{Modified Born rule with entropic amplitude}

Cross-level interference during projection introduces corrections:

\begin{prediction}[Born rule oscillations with entropic amplitude]
\label{pred:born}
The probability of measurement outcome $k$ is:
\begin{equation}
P_k = |\langle k|\psi\rangle|^2 + A(n) \cdot \sin\left(\frac{2\pi \tau(n)}{T}\right)
\end{equation}
where:
\begin{itemize}
\item $A(n) \propto 1/(n \log n)$ is the oscillation amplitude (entropic decay)
\item $\tau(n) = \tau_0 + \gamma n \log n$ is the measurement delay
\item $T = h/\Delta E$ is the oscillation period set by energy scale
\end{itemize}
\end{prediction}

The $1/(n \log n)$ amplitude decay reflects the entropic information capacity at level $n$.

\subsection{Experimental signatures}

For a 10-qubit system:
\begin{itemize}
\item Information capacity: $I(10) = 10\kappa \log 10 \approx 33\kappa$ bits
\item Measurement delay: $\tau(10) = \tau_0 + 33\gamma$ (in appropriate units)
\item Oscillation amplitude: $A(10) \propto 1/33 \approx 3\%$
\end{itemize}

These effects should be observable with current quantum computing platforms.

\section{Thermodynamic Implications}
\label{sec:thermo}

\subsection{Modified Landauer bound with entropic scaling}

Projection erases information, requiring energy dissipation:

\begin{proposition}[Entropic Landauer bound]
Projecting from level $j$ to $i < j$ dissipates minimum energy:
\begin{equation}
E_{\text{min}} = k_B T \cdot I(j-i) \ln 2 = k_B T \cdot \kappa (j-i) \log(j-i) \ln 2
\end{equation}
where $I(n) = \kappa n \log n$ is the information erased.
\end{proposition}

For quantum measurements, $\kappa \gg 1$ due to decoherence overhead, consistent with experimental observations \cite{landauer1961,bennett1982}.

\section{Experimental Protocols}
\label{sec:experiments}

\subsection{Protocol 1: Measuring entropic delay scaling}

\textbf{Setup:} Ion trap or superconducting qubit system
\textbf{Procedure:}
\begin{enumerate}
\item Prepare $n$-qubit GHZ state: $|\psi\rangle = (|0\rangle^{\otimes n} + |1\rangle^{\otimes n})/\sqrt{2}$
\item Initiate measurement at time $t = 0$
\item Monitor measurement completion time $\tau_{\text{meas}}(n)$
\item Repeat for $n = 5, 10, 15, 20$ qubits
\item Fit to $\tau(n) = \tau_0 + \gamma n \log n$
\end{enumerate}

\textbf{Expected result:} Entropic scaling with $\gamma \approx 10^{-9}$ s per bit (system-dependent)

\subsection{Protocol 2: Detecting Born rule oscillations}

\textbf{Setup:} High-precision single-qubit measurement
\textbf{Procedure:}
\begin{enumerate}
\item Prepare superposition $|\psi\rangle = \alpha|0\rangle + \beta|1\rangle$
\item Perform measurements at varying delays $t \in [0, 100\tau(n)]$
\item Record outcome probabilities $P_0(t), P_1(t)$
\item Fourier analyze for oscillations at frequency $1/T$
\item Verify amplitude scales as $A(n) \propto 1/(n \log n)$
\end{enumerate}

\textbf{Expected result:} Oscillations with 1--5\% amplitude following entropic decay

\section{Falsification Criteria}
\label{sec:falsification}

The framework is falsified if:
\begin{enumerate}
\item Measurement time shows no dependence on qubit number $n$
\item Scaling follows $\tau \propto n$ (linear) or $\tau \propto n^2$ (quadratic) rather than $n \log n$
\item No oscillatory corrections to Born rule are detected within sensitivity limits
\item Oscillation amplitude doesn't follow $1/(n \log n)$ decay
\end{enumerate}

Current technology can test these predictions at the required precision.

\section{Conclusion}
\label{sec:conclusion}

We have proposed a hierarchical projection model of quantum measurement with entropic scaling, predicting:
\begin{enumerate}
\item Measurement delay $\tau(n) = \tau_0 + \gamma n \log n$
\item Born rule corrections with amplitude $A(n) \propto 1/(n \log n)$
\end{enumerate}

These predictions are testable with current quantum computing platforms. The entropic scaling provides more realistic computational complexity than exponential alternatives while maintaining theoretical rigor.

\textbf{Critical assessment:}
\begin{itemize}
\item \textbf{Strengths:} Concrete falsifiable predictions, explicit mathematical framework via adjunction $(C_Q \dashv P_Q)$, rigorous categorical structure with entropic scaling
\item \textbf{Weaknesses:} Lacks complete physical justification, entropic scaling is empirically motivated, potential conflicts with established decoherence theory
\end{itemize}

This work should be viewed as \textbf{highly speculative} but \textbf{rigorously testable}. The predictions may be false, but testing them constrains how computation relates to quantum mechanics. Even negative results advance our understanding.

The framework reframes collapse from axiom to algorithm with entropic complexity, but whether nature actually performs this algorithm remains an open---and skepticism-inducing---question.

\begin{thebibliography}{10}

\bibitem{abramsky2004}
Abramsky, S., \& Coecke, B. (2004).
\newblock A categorical semantics of quantum protocols.
\newblock \emph{Proceedings of LICS}, 415--425.

\bibitem{bennett1982}
Bennett, C. H. (1982).
\newblock The thermodynamics of computation---a review.
\newblock \emph{International Journal of Theoretical Physics}, 21(12), 905--940.

\bibitem{deutsch2015}
Deutsch, D., \& Marletto, C. (2015).
\newblock Constructor theory of information.
\newblock \emph{Proceedings of the Royal Society A}, 471(2174), 20140540.

\bibitem{fuchs1999}
Fuchs, C. A., \& Van De Graaf, J. (1999).
\newblock Cryptographic distinguishability measures for quantum-mechanical states.
\newblock \emph{IEEE Transactions on Information Theory}, 45(4), 1216--1227.

\bibitem{joos2003}
Joos, E., et al. (2003).
\newblock \emph{Decoherence and the Appearance of a Classical World in Quantum Theory} (2nd ed.).
\newblock Springer.

\bibitem{kowalczyk2025}
Kowalczyk, K. (2025).
\newblock Adjoint projections on computational hierarchies: A metric framework with entropic scaling.
\newblock \emph{Manuscript in preparation}.

\bibitem{landauer1961}
Landauer, R. (1961).
\newblock Irreversibility and heat generation in the computing process.
\newblock \emph{IBM Journal of Research and Development}, 5(3), 183--191.

\bibitem{nielsen2010}
Nielsen, M. A., \& Chuang, I. L. (2010).
\newblock \emph{Quantum Computation and Quantum Information} (10th Anniversary Edition).
\newblock Cambridge University Press.

\bibitem{penrose1996}
Penrose, R. (1996).
\newblock On gravity's role in quantum state reduction.
\newblock \emph{General Relativity and Gravitation}, 28(5), 581--600.

\bibitem{schlosshauer2007}
Schlosshauer, M. (2007).
\newblock \emph{Decoherence and the Quantum-to-Classical Transition}.
\newblock Springer.

\bibitem{zurek2003}
Zurek, W. H. (2003).
\newblock Decoherence, einselection, and the quantum origins of the classical.
\newblock \emph{Reviews of Modern Physics}, 75(3), 715--775.

\bibitem{zurek2009}
Zurek, W. H. (2009).
\newblock Quantum Darwinism.
\newblock \emph{Nature Physics}, 5(3), 181--188.

\end{thebibliography}

\end{document}
