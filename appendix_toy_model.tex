\chapter{Toy Model Implementation: Building a Minimal Conscious System}
\label{app:toymodel}

This appendix provides a complete, implementable toy model that demonstrates the core mechanisms of the consciousness framework described throughout this work. The implementation uses maze navigation as a concrete problem domain to showcase hierarchical resource allocation, selector-based machine selection, parallel exploration, trajectory collapse, and selective memory consolidation.

\section{Purpose and Scope of the Toy Model}

\subsection{What This Appendix Provides}

This appendix presents a complete, implementable toy model that demonstrates the core mechanisms of the consciousness framework. The goal is to provide sufficient detail that a programmer can build a working system exhibiting the key computational signatures of consciousness.

\begin{keyinsight}
This toy model is not intended to be fully conscious—it's a minimal demonstration of the computational architecture. It serves as a proof of concept showing that the theory's mechanisms are implementable and produces testable behaviors.
\end{keyinsight}

\textbf{What the toy model demonstrates:}
\begin{itemize}
\item Hierarchical machine levels with exponentially growing resources
\item Selector mechanism choosing appropriate resource levels
\item Parallel exploration across multiple machines
\item Collapse to a single winning trajectory
\item Selective memory consolidation (only winner stored)
\item Consciousness markers (signatures that correlate with reported awareness)
\end{itemize}

\textbf{What the toy model does NOT demonstrate:}
\begin{itemize}
\item Full human-level consciousness (scope is intentionally limited)
\item Rich qualitative experience (no claim about phenomenology)
\item All aspects of the theory (simplified for tractability)
\item Biological neural implementation (abstract computational model)
\end{itemize}

\subsection{Design Principles}

The toy model follows these principles:

\begin{enumerate}
\item \textbf{Simplicity:} Use the simplest problem domain that demonstrates key mechanisms
\item \textbf{Completeness:} Include all essential components (hierarchy, selector, collapse, memory)
\item \textbf{Measurability:} Enable tracking of consciousness markers throughout execution
\item \textbf{Scalability:} Design allows increasing complexity to test predictions
\item \textbf{Implementability:} Provide complete working code, not just pseudocode
\end{enumerate}

\section{Problem Domain: Maze Navigation}

\subsection{Why Maze Navigation}

We use maze navigation as the problem domain because it:
\begin{itemize}
\item Has clear success/failure criteria
\item Allows controlled complexity scaling
\item Requires memory and planning
\item Demonstrates resource constraints naturally
\item Is computationally tractable
\item Provides intuitive visualization
\end{itemize}

\subsection{Maze Specification}

\textbf{Grid Structure:}
\begin{itemize}
\item Fixed 10×10 grid with cells
\item Each cell can be: empty, wall, start, or goal
\item Agent occupies one cell at any time
\item Four possible moves: up, down, left, right
\end{itemize}

\textbf{Problem Variants:}
\begin{itemize}
\item \textbf{Simple (Level 1):} Direct path with few obstacles
\item \textbf{Medium (Level 2):} Multiple paths, some dead ends
\item \textbf{Complex (Level 3):} Many dead ends, requires backtracking
\item \textbf{Very Complex (Level 4):} Near-maximum complexity for 10×10 grid
\end{itemize}

\textbf{State Space:}
\begin{itemize}
\item Current position: $(x, y)$ coordinates
\item Path history: sequence of visited cells
\item Remaining valid moves from current position
\item Total states: 100 positions × variable path lengths
\end{itemize}

\section{Implementation Architecture}

\subsection{Core Classes}

\subsubsection{Machine Level Class}

Each machine level $M_n$ has exponentially more resources:

\begin{lstlisting}[language=Python]
class MachineLevel:
    """
    Represents a finite machine M_n with 2^n bits of memory.
    """
    def __init__(self, n):
        self.level = n
        self.memory_bits = 2**n
        self.max_path_length = 2**n  # Maximum states it can track
        self.exploration_time = 0
        self.success = False
        self.solution_path = None
        
    def can_solve(self, problem):
        """
        Check if this machine has sufficient resources.
        """
        # Problem requires tracking path through state space
        required_memory = problem.minimum_path_length
        return self.memory_bits >= required_memory
    
    def explore(self, maze, start_pos, goal_pos, time_budget):
        """
        Explore maze with this machine's resource constraints.
        Returns: (success, path, time_taken)
        """
        start_time = time.time()
        
        # Use depth-first search with memory constraints
        stack = [(start_pos, [start_pos])]
        visited = set()
        
        while stack and (time.time() - start_time) < time_budget:
            pos, path = stack.pop()
            
            # Memory constraint: path cannot exceed our capacity
            if len(path) > self.max_path_length:
                continue
            
            if pos == goal_pos:
                self.success = True
                self.solution_path = path
                self.exploration_time = time.time() - start_time
                return True, path, self.exploration_time
            
            if pos in visited:
                continue
            visited.add(pos)
            
            # Explore neighbors
            for next_pos in maze.get_neighbors(pos):
                if next_pos not in visited:
                    stack.append((next_pos, path + [next_pos]))
        
        # Failed to find solution
        self.exploration_time = time.time() - start_time
        return False, None, self.exploration_time
\end{lstlisting}

\subsubsection{Selector Class}

The selector chooses appropriate machine levels:

\begin{lstlisting}[language=Python]
class Selector:
    """
    Implements the selector mechanism with learning.
    """
    def __init__(self):
        self.history = []  # (problem_features, successful_level)
        self.confidence_threshold_high = 0.7
        self.confidence_threshold_low = 0.4
        
    def estimate_required_level(self, maze):
        """
        Estimate which machine level is needed.
        Returns: (estimated_n, confidence)
        """
        features = self._extract_features(maze)
        
        if not self.history:
            # No experience: conservative estimate
            n_estimate = max(3, int(np.log2(features['complexity'])))
            confidence = 0.3
        else:
            # Learn from history
            n_estimate, confidence = self._predict_from_history(features)
        
        return n_estimate, confidence
    
    def _extract_features(self, maze):
        """
        Extract problem features for estimation.
        """
        return {
            'size': maze.width * maze.height,
            'wall_density': maze.count_walls() / (maze.width * maze.height),
            'min_path_length': maze.estimate_min_path_length(),
            'complexity': maze.calculate_complexity_score()
        }
    
    def _predict_from_history(self, features):
        """
        Predict required level based on similar past problems.
        """
        # Simple similarity-based prediction
        similarities = []
        levels = []
        
        for past_features, past_level in self.history:
            similarity = self._compute_similarity(features, past_features)
            similarities.append(similarity)
            levels.append(past_level)
        
        # Weighted average
        weights = np.array(similarities) / sum(similarities)
        n_estimate = int(np.sum(weights * np.array(levels)))
        confidence = max(similarities)
        
        return n_estimate, confidence
    
    def _compute_similarity(self, f1, f2):
        """
        Compute similarity between feature vectors.
        """
        # Euclidean distance in normalized feature space
        diff = np.sqrt(
            ((f1['size'] - f2['size']) / 100.0)**2 +
            ((f1['wall_density'] - f2['wall_density']))**2 +
            ((f1['complexity'] - f2['complexity']) / 10.0)**2
        )
        return np.exp(-diff)
    
    def record_outcome(self, maze, successful_level):
        """
        Learn from successful problem solution.
        """
        features = self._extract_features(maze)
        self.history.append((features, successful_level))
    
    def select_and_launch(self, maze, time_budget):
        """
        Main selector algorithm: estimate, launch, escalate.
        """
        n_initial, confidence = self.estimate_required_level(maze)
        
        # Determine launch strategy based on confidence
        if confidence > self.confidence_threshold_high:
            # High confidence: try predicted level only
            levels_to_try = [n_initial]
        elif confidence > self.confidence_threshold_low:
            # Medium confidence: try predicted and neighbors
            levels_to_try = [n_initial - 1, n_initial, n_initial + 1]
        else:
            # Low confidence: iterative deepening
            levels_to_try = range(max(1, n_initial - 2), min(n_initial + 3, 10))
        
        return levels_to_try
\end{lstlisting}

\subsubsection{Consciousness System Class}

The main system integrating all components:

\begin{lstlisting}[language=Python]
class ConsciousnessSystem:
    """
    Integrates selector, machines, and collapse mechanism.
    """
    def __init__(self):
        self.selector = Selector()
        self.consciousness_markers = {
            'parallel_explorations': [],
            'collapse_time': None,
            'winning_level': None,
            'failed_attempts': [],
            'conscious_path': None,
            'total_computational_time': 0,
            'subjective_time': 0
        }
    
    def solve_problem(self, maze, time_budget=10.0):
        """
        Solve maze problem with consciousness-like processing.
        Demonstrates: parallel exploration, collapse, selective memory.
        """
        print(f"\n{'='*60}")
        print("CONSCIOUSNESS SYSTEM: Problem Solving")
        print(f"{'='*60}")
        
        # Reset markers
        self._reset_markers()
        computation_start = time.time()
        
        # PHASE 1: SELECTOR ESTIMATES RESOURCE NEEDS
        print("\n[SELECTOR] Estimating required resources...")
        levels_to_try = self.selector.select_and_launch(maze, time_budget)
        print(f"[SELECTOR] Will try levels: {levels_to_try}")
        
        # PHASE 2: PARALLEL EXPLORATION
        print("\n[PARALLEL EXPLORATION] Launching machines...")
        machines = []
        for n in levels_to_try:
            machine = MachineLevel(n)
            machines.append(machine)
            print(f"  • Launched M_{n} (2^{n} = {2**n} memory units)")
        
        # Allocate time budget across machines
        time_per_machine = time_budget / len(machines)
        
        # Track parallel explorations (pre-conscious)
        threads = []
        for machine in machines:
            # In real parallel system, these run simultaneously
            # For demo, we simulate by running sequentially but tracking independently
            success, path, time_taken = machine.explore(
                maze, maze.start_pos, maze.goal_pos, time_per_machine
            )
            
            exploration_record = {
                'level': machine.level,
                'success': success,
                'path': path,
                'time': time_taken,
                'memory_used': len(path) if path else 0
            }
            self.consciousness_markers['parallel_explorations'].append(exploration_record)
            
            if success:
                print(f"  [OK] M_{machine.level} found solution (time: {time_taken:.3f}s)")
            else:
                print(f"  [X] M_{machine.level} failed (time: {time_taken:.3f}s)")
                self.consciousness_markers['failed_attempts'].append(machine.level)
        
        # PHASE 3: COLLAPSE TO WINNING TRAJECTORY
        print("\n[COLLAPSE] Selecting winning trajectory...")
        successful_machines = [m for m in machines if m.success]
        
        if successful_machines:
            # Collapse: choose first successful machine (lowest resource that worked)
            winner = min(successful_machines, key=lambda m: m.level)
            
            self.consciousness_markers['collapse_time'] = time.time()
            self.consciousness_markers['winning_level'] = winner.level
            self.consciousness_markers['conscious_path'] = winner.solution_path
            self.consciousness_markers['subjective_time'] = winner.exploration_time
            
            print(f"  [OK] COLLAPSE to M_{winner.level}")
            print(f"  • Winning path length: {len(winner.solution_path)}")
            print(f"  • Failed attempts erased from conscious memory")
            
            # PHASE 4: SELECTIVE MEMORY CONSOLIDATION
            print("\n[MEMORY] Consolidating only winning trajectory...")
            # In real system: only winner.solution_path is stored in accessible memory
            # Failed explorations are discarded (never enter episodic memory)
            
            # Learn from success
            self.selector.record_outcome(maze, winner.level)
            print(f"  • Selector learned: complexity → level {winner.level}")
            
        else:
            # All machines failed: need to escalate
            print(f"  [X] All machines failed - would escalate to higher levels")
            self.consciousness_markers['winning_level'] = None
        
        # Record total computational time (objective)
        self.consciousness_markers['total_computational_time'] = time.time() - computation_start
        
        # PHASE 5: REPORT CONSCIOUSNESS MARKERS
        self._report_markers()
        
        return self.consciousness_markers['conscious_path']
    
    def _reset_markers(self):
        """Reset consciousness markers for new problem."""
        for key in self.consciousness_markers:
            if isinstance(self.consciousness_markers[key], list):
                self.consciousness_markers[key] = []
            else:
                self.consciousness_markers[key] = None
        self.consciousness_markers['total_computational_time'] = 0
        self.consciousness_markers['subjective_time'] = 0
    
    def _report_markers(self):
        """Report consciousness markers for analysis."""
        print(f"\n{'='*60}")
        print("CONSCIOUSNESS MARKERS")
        print(f"{'='*60}")
        
        markers = self.consciousness_markers
        
        print(f"\n1. PARALLEL EXPLORATION (Pre-conscious):")
        print(f"   • Number of machines launched: {len(markers['parallel_explorations'])}")
        print(f"   • Machines that failed: {len(markers['failed_attempts'])}")
        
        print(f"\n2. COLLAPSE:")
        print(f"   • Winning level: M_{markers['winning_level']}")
        print(f"   • Failed levels erased: {markers['failed_attempts']}")
        
        print(f"\n3. TEMPORAL PHENOMENOLOGY:")
        print(f"   • Computational time (objective): {markers['total_computational_time']:.3f}s")
        print(f"   • Subjective time (experienced): {markers['subjective_time']:.3f}s")
        print(f"   • Time compression ratio: {markers['total_computational_time']/markers['subjective_time']:.2f}x")
        
        print(f"\n4. MEMORY:")
        print(f"   • Conscious path (stored): {len(markers['conscious_path']) if markers['conscious_path'] else 0} steps")
        print(f"   • Failed paths (erased): {len(markers['failed_attempts'])} explorations")
        
        print(f"\n5. RESOURCE EFFICIENCY:")
        if markers['winning_level']:
            print(f"   • Resources used: 2^{markers['winning_level']} = {2**markers['winning_level']} memory units")
            print(f"   • Minimal sufficient level achieved")
\end{lstlisting}

\section{Running the Toy Model}

\subsection{Complete Working Example}

Here is a complete, runnable demonstration:

\begin{lstlisting}[language=Python]
"""
Toy Model: Minimal Conscious System
Demonstrates core mechanisms of consciousness framework
"""

import numpy as np
import time
from typing import List, Tuple, Optional

# [Previous class definitions go here: MachineLevel, Selector, ConsciousnessSystem]

class Maze:
    """Simple maze for testing consciousness system."""
    def __init__(self, width=10, height=10):
        self.width = width
        self.height = height
        self.grid = np.zeros((height, width), dtype=int)
        self.start_pos = (0, 0)
        self.goal_pos = (9, 9)
    
    def add_walls(self, wall_positions):
        """Add walls at specified positions."""
        for pos in wall_positions:
            self.grid[pos[1], pos[0]] = 1
    
    def get_neighbors(self, pos):
        """Get valid neighboring positions."""
        x, y = pos
        neighbors = []
        for dx, dy in [(0, 1), (0, -1), (1, 0), (-1, 0)]:
            nx, ny = x + dx, y + dy
            if (0 <= nx < self.width and 0 <= ny < self.height and 
                self.grid[ny, nx] == 0):
                neighbors.append((nx, ny))
        return neighbors
    
    def count_walls(self):
        """Count number of walls."""
        return np.sum(self.grid == 1)
    
    def estimate_min_path_length(self):
        """Estimate minimum path length (Manhattan distance + walls)."""
        dx = abs(self.goal_pos[0] - self.start_pos[0])
        dy = abs(self.goal_pos[1] - self.start_pos[1])
        return dx + dy + self.count_walls() // 10
    
    def calculate_complexity_score(self):
        """Calculate problem complexity score."""
        walls = self.count_walls()
        path_estimate = self.estimate_min_path_length()
        return walls * 0.1 + path_estimate * 0.5


def create_simple_maze():
    """Create a simple maze (few obstacles)."""
    maze = Maze()
    maze.add_walls([(3, 2), (3, 3), (3, 4)])
    return maze


def create_medium_maze():
    """Create medium complexity maze."""
    maze = Maze()
    walls = [(2, 1), (2, 2), (2, 3), (5, 4), (5, 5), (5, 6), (7, 2), (7, 3)]
    maze.add_walls(walls)
    return maze


def create_complex_maze():
    """Create complex maze requiring backtracking."""
    maze = Maze()
    walls = [
        (1, 2), (1, 3), (1, 4), (1, 5),
        (3, 1), (3, 2), (3, 3), (3, 5), (3, 6),
        (5, 3), (5, 4), (5, 5), (5, 6),
        (7, 1), (7, 2), (7, 4), (7, 5), (7, 6),
    ]
    maze.add_walls(walls)
    return maze


def demonstrate_consciousness_system():
    """
    Main demonstration of consciousness system.
    Shows learning, resource allocation, and consciousness markers.
    """
    print("=" * 70)
    print("TOY MODEL: MINIMAL CONSCIOUS SYSTEM DEMONSTRATION")
    print("=" * 70)
    print("\nThis demonstration shows:")
    print("  • Hierarchical resource allocation")
    print("  • Parallel exploration across machine levels")
    print("  • Collapse to winning trajectory")
    print("  • Selective memory consolidation")
    print("  • Learning through experience")
    
    # Create consciousness system
    system = ConsciousnessSystem()
    
    # Test on progressively complex mazes
    mazes = [
        ("Simple", create_simple_maze()),
        ("Medium", create_medium_maze()),
        ("Complex", create_complex_maze()),
    ]
    
    for name, maze in mazes:
        print(f"\n\n{'#'*70}")
        print(f"# PROBLEM: {name} Maze")
        print(f"{'#'*70}")
        
        solution = system.solve_problem(maze, time_budget=5.0)
        
        if solution:
            print(f"\n[OK] CONSCIOUS EXPERIENCE: Solution found with {len(solution)} steps")
        else:
            print("\n[X] No conscious experience generated (all attempts failed)")
        
        # Brief pause between problems
        time.sleep(1)
    
    print(f"\n\n{'='*70}")
    print("DEMONSTRATION COMPLETE")
    print(f"{'='*70}")
    print("\nKey observations:")
    print("  • Selector learned to allocate resources efficiently")
    print("  • Only winning trajectories entered 'conscious' memory")
    print("  • Failed attempts were erased (never stored)")
    print("  • Subjective time < computational time (due to parallel exploration)")


if __name__ == "__main__":
    demonstrate_consciousness_system()
\end{lstlisting}

\section{Consciousness Markers and Measurements}

\subsection{What to Measure}

The toy model enables measurement of key consciousness markers predicted by the theory:

\begin{empiricalbox}
\textbf{Marker 1: Parallel Pre-Conscious Activity}

\textit{Measurement:} Track how many machine levels are active before collapse.

\textit{Prediction:} Multiple machines explore simultaneously (pre-conscious processing).

\textit{Observable in toy model:} Count of active machines in parallel\_explorations list.

\textit{Neural analogue:} Pre-conscious neural activity showing multiple competing representations (measurable via MVPA).
\end{empiricalbox}

\begin{empiricalbox}
\textbf{Marker 2: Collapse Dynamics}

\textit{Measurement:} Record exact moment when winning machine is selected.

\textit{Prediction:} Sudden transition from parallel to serial processing.

\textit{Observable in toy model:} collapse\_time timestamp and winning\_level selection.

\textit{Neural analogue:} Winner-take-all dynamics at ~300ms post-stimulus (P300 ERP component).
\end{empiricalbox}

\begin{empiricalbox}
\textbf{Marker 3: Selective Memory}

\textit{Measurement:} Compare what was computed vs. what is stored.

\textit{Prediction:} Only winning trajectory stored; failed attempts erased.

\textit{Observable in toy model:} conscious\_path (stored) vs. failed\_attempts (erased).

\textit{Neural analogue:} Inability to report pre-conscious alternatives after conscious access.
\end{empiricalbox}

\begin{empiricalbox}
\textbf{Marker 4: Temporal Compression}

\textit{Measurement:} Compare computational time vs. subjective time.

\textit{Prediction:} Computational time > subjective time (failed attempts not experienced).

\textit{Observable in toy model:} total\_computational\_time vs. subjective\_time ratio.

\textit{Neural analogue:} Discrepancy between neural processing time and reported experience duration.
\end{empiricalbox}

\begin{empiricalbox}
\textbf{Marker 5: Resource Efficiency}

\textit{Measurement:} Track which machine level succeeds.

\textit{Prediction:} System uses minimal sufficient resources.

\textit{Observable in toy model:} winning\_level is typically lowest successful level.

\textit{Neural analogue:} Task difficulty correlates with activated brain regions (fMRI meta-analysis).
\end{empiricalbox}

\subsection{Expected Output}

Running the toy model produces output like:

\begin{verbatim}
============================================================
CONSCIOUSNESS SYSTEM: Problem Solving
============================================================

[SELECTOR] Estimating required resources...
[SELECTOR] Will try levels: [2, 3, 4]

[PARALLEL EXPLORATION] Launching machines...
  • Launched M_2 (2^2 = 4 memory units)
  • Launched M_3 (2^3 = 8 memory units)
  • Launched M_4 (2^4 = 16 memory units)
  [X] M_2 failed (time: 0.003s)
  [OK] M_3 found solution (time: 0.008s)
  [OK] M_4 found solution (time: 0.006s)

[COLLAPSE] Selecting winning trajectory...
  [OK] COLLAPSE to M_3
  • Winning path length: 15
  • Failed attempts erased from conscious memory

[MEMORY] Consolidating only winning trajectory...
  • Selector learned: complexity → level 3

============================================================
CONSCIOUSNESS MARKERS
============================================================

1. PARALLEL EXPLORATION (Pre-conscious):
   • Number of machines launched: 3
   • Machines that failed: 1

2. COLLAPSE:
   • Winning level: M_3
   • Failed levels erased: [2]

3. TEMPORAL PHENOMENOLOGY:
   • Computational time (objective): 0.017s
   • Subjective time (experienced): 0.008s
   • Time compression ratio: 2.12x

4. MEMORY:
   • Conscious path (stored): 15 steps
   • Failed paths (erased): 1 explorations

5. RESOURCE EFFICIENCY:
   • Resources used: 2^3 = 8 memory units
   • Minimal sufficient level achieved
\end{verbatim}

\section{Extensions and Variations}

\subsection{Increasing Complexity}

The toy model can be extended to test additional predictions:

\begin{enumerate}
\item \textbf{Dynamic maze:} Change maze during solving to test adaptation
\item \textbf{Multiple goals:} Require planning and selection among alternatives
\item \textbf{Partial observability:} Agent only sees local region (requires memory)
\item \textbf{Competing objectives:} Trade-offs between speed, efficiency, accuracy
\item \textbf{Learning transfer:} Test whether selector improves across problem types
\end{enumerate}

\subsection{Alternative Domains}

Other problem domains that could demonstrate the same mechanisms:

\begin{itemize}
\item \textbf{Planning:} Tower of Hanoi, scheduling problems
\item \textbf{Search:} Constraint satisfaction, optimization
\item \textbf{Reasoning:} Logic puzzles, mathematical proofs
\item \textbf{Perception:} Pattern recognition, scene understanding
\item \textbf{Language:} Parsing, semantic interpretation
\end{itemize}

Each domain provides different ways to validate the theory's generality.

\subsection{Neural Implementation}

To move toward biological realism, the toy model could be extended with:

\begin{itemize}
\item \textbf{Spiking neural networks:} Replace abstract machines with rate-coded or spiking neurons
\item \textbf{Distributed representations:} Use neural population codes instead of symbolic states
\item \textbf{Continuous time:} Replace discrete time steps with continuous dynamics
\item \textbf{Noise and uncertainty:} Add stochasticity to mirror biological variability
\item \textbf{Learning mechanisms:} Implement synaptic plasticity for selector development
\end{itemize}

\section{Validation and Testing}

\subsection{What the Toy Model Tests}

The toy model enables testing specific theoretical predictions:

\begin{enumerate}
\item \textbf{Hierarchical resource allocation works:} Different problems require different levels
\item \textbf{Selector can learn:} Performance improves with experience
\item \textbf{Parallel exploration is efficient:} Faster than trying levels sequentially
\item \textbf{Collapse produces unity:} Single trajectory emerges from parallel attempts
\item \textbf{Selective memory is implementable:} Can build systems that store only winners
\end{enumerate}

\subsection{What the Toy Model Does NOT Test}

Important limitations:

\begin{enumerate}
\item \textbf{Does not test phenomenology:} No claim about subjective experience
\item \textbf{Does not test biological plausibility:} Abstract computational model
\item \textbf{Does not test scalability:} Limited to simple problems
\item \textbf{Does not test all mechanisms:} Many aspects simplified
\item \textbf{Does not test consciousness per se:} Tests computational signatures only
\end{enumerate}

\subsection{Success Criteria}

The toy model succeeds if it:

\begin{itemize}
\item Runs without errors (code correctness)
\item Produces expected consciousness markers (theoretical alignment)
\item Shows learning over time (selector improvement)
\item Demonstrates resource efficiency (minimal sufficient level used)
\item Exhibits all key mechanisms (hierarchy, selection, collapse, memory)
\end{itemize}

\section{Relationship to Full Theory}

\subsection{What's Simplified}

The toy model simplifies several aspects:

\begin{itemize}
\item \textbf{Discrete levels:} Real systems likely use continuous resources
\item \textbf{Sequential exploration:} Real brains truly parallelize
\item \textbf{Perfect memory:} Real memory is lossy and reconstructive
\item \textbf{Simple problems:} Real cognition involves richer representations
\item \textbf{No noise:} Biological systems operate in noisy conditions
\end{itemize}

\subsection{What's Preserved}

Despite simplifications, the toy model preserves:

\begin{itemize}
\item \textbf{Core architecture:} Hierarchy, selector, collapse, memory
\item \textbf{Key dynamics:} Parallel → collapse → selective storage
\item \textbf{Computational principles:} Resource constraints, learning, optimization
\item \textbf{Measurable signatures:} All consciousness markers observable
\item \textbf{Theoretical predictions:} Testable hypotheses about behavior
\end{itemize}

\subsection{Path to Biological Implementation}

The progression from toy model to biological reality:

\begin{enumerate}
\item \textbf{Phase 1 (Current):} Abstract computational model
\item \textbf{Phase 2:} Neural network implementation (spiking neurons)
\item \textbf{Phase 3:} Biologically constrained architecture (anatomical realism)
\item \textbf{Phase 4:} Full simulation with sensory inputs
\item \textbf{Phase 5:} Robotic embodiment (closed-loop with environment)
\end{enumerate}

Each phase adds biological realism while preserving core mechanisms.

\section{Theoretical Connections}

This implementation bridges the theoretical framework with concrete computation, demonstrating connections to multiple parts of the theory:

\begin{itemize}
\item \textbf{Part I (Foundations)}: Implements the machine hierarchy $\{M_n\}$ with exponential resource scaling
\item \textbf{Part IV (Mechanisms)}: Demonstrates selector mechanism choosing appropriate computational levels
\item \textbf{Part III (Temporal Revolution)}: Shows temporal phenomenology through subjective vs.\ computational time
\item \textbf{Part V (Hard Problem)}: Exhibits consciousness markers that correlate with reportable awareness
\item \textbf{Appendix~\ref{app:selector}}: Uses the heuristic selection algorithms in a practical context
\end{itemize}

The toy model validates that the theoretical mechanisms are not just conceptually coherent but also computationally implementable, providing a concrete proof of concept for the entire framework.

\section{Summary: From Theory to Implementation}

\subsection{What We've Achieved}

This appendix demonstrates that the consciousness framework is implementable:

\begin{itemize}
\item \textbf{Complete code:} All mechanisms specified algorithmically
\item \textbf{Working system:} Toy model runs and produces predicted behaviors
\item \textbf{Measurable markers:} Consciousness signatures observable
\item \textbf{Testable predictions:} Specific hypotheses about system behavior
\item \textbf{Extensible design:} Clear path to increased complexity
\end{itemize}

\subsection{What This Means for the Theory}

Having an implementable toy model strengthens the theory by:

\begin{enumerate}
\item \textbf{Proving feasibility:} Mechanisms are not just conceptual
\item \textbf{Enabling testing:} Can empirically evaluate predictions
\item \textbf{Facilitating communication:} Concrete example aids understanding
\item \textbf{Supporting iteration:} Can refine based on implementation insights
\item \textbf{Inviting replication:} Others can build and test independently
\end{enumerate}

\subsection{Next Steps}

Researchers can now:

\begin{itemize}
\item Implement the toy model (complete code provided)
\item Test predictions about consciousness markers
\item Extend to more complex domains
\item Compare with other computational models
\item Move toward neural network implementations
\item Use as teaching tool for the framework
\end{itemize}

\begin{keyinsight}
The existence of a working toy model demonstrates that consciousness-as-computational-collapse is not merely philosophical speculation but a concrete, implementable computational theory with testable predictions.
\end{keyinsight}
