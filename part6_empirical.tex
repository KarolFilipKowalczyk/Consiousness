% ============================================================================
% PART VI: EMPIRICAL PREDICTIONS AND TESTING
% ============================================================================

\part{Empirical Predictions and Testing}

% ============================================================================
% CHAPTER 17: TESTABLE PREDICTIONS
% ============================================================================

\chapter{Testable Predictions: From Theory to Experiment}

\section{The Empirical Challenge}

\subsection{Why Testability Matters}

\begin{keyinsight}
A theory of consciousness must be more than philosophically coherent—it must make specific, testable predictions that distinguish it from alternatives and expose it to potential falsification. Our framework makes numerous concrete predictions spanning neural correlates of consciousness, patterns of brain activity, behavioral signatures, clinical conditions, evolutionary patterns, and artificial systems. These predictions can be tested with current or near-future neuroscience methods.
\end{keyinsight}

\subsection{Prediction Categories}

\begin{definition}[Types of Predictions]
Our predictions fall into several categories, each providing multiple opportunities for empirical testing. Structural predictions address what neural architecture is necessary for consciousness to arise. Dynamic predictions specify what temporal patterns should occur during conscious processing. Causal predictions indicate what interventions should affect consciousness and how. Graded predictions describe how consciousness varies quantitatively with resource availability. Pathological predictions explain what happens when systems break down or become damaged. Finally, comparative predictions specify how consciousness should differ across species and between biological and artificial systems.
\end{definition}

\subsection{Contrast with Existing Theories}

\begin{proposition}[Distinguishing Our Framework]
Our predictions differ from other theories in specific ways. Compared to IIT \autocite{tononi2016}, we predict not just integration but a hierarchy of resource levels, temporal collapse signatures observable in neural dynamics, and a non-computable selector mechanism that determines resource deployment. Compared to GWT \autocite{baars1997}, we predict parallel exploration occurring before any broadcast mechanism, resource-level selection that explains capacity limits, and temporal erasure of failed computational paths invisible to consciousness. Compared to AST \autocite{graziano2019}, we predict a computational substrate underlying the attention schema itself, resource-dependent metacognition that varies with available computational power, and specific collapse dynamics that generate the illusion of unified attention. These differences create testable contrasts that can empirically distinguish our framework from alternatives.
\end{proposition}

\section{Prediction 1: Machine Hierarchy Signatures}

\subsection{The Core Prediction}

\begin{empiricalbox}
\textbf{Prediction 1.1: Hierarchical Resource Levels}

The brain implements a discrete hierarchy of computational machines $M_1, M_2, \ldots, M_n$ with exponentially increasing resources. We expect to find distinct neural populations or networks dedicated to different resource levels, with exponential scaling in representational capacity rather than smooth gradation. Processing power should exhibit discrete jumps, with higher resource levels recruited only when lower levels prove insufficient for the task at hand.

\textbf{Measurement approaches}: This prediction can be tested through multi-unit recording during tasks of varying complexity, fMRI with parametrically varied task demands, information-theoretic analysis of neural codes, and computational modeling of network capacity limits.
\end{empiricalbox}

\subsection{Specific Neural Signatures}

\begin{empiricalbox}
\textbf{Prediction 1.2: Level-Specific Networks}

Different brain regions implement different machine levels in our framework. Low $n$ machines, supporting automatic processing, should map to primary sensory cortices, basal ganglia, cerebellum, and local cortical circuits. Medium $n$ machines, corresponding to typical conscious experience, should engage prefrontal cortex, parietal cortex, temporal association areas, and thalamo-cortical loops. High $n$ machines, activated during intense focused attention, should recruit dorsolateral prefrontal cortex, anterior cingulate cortex, extended parietal networks, and widely distributed integration zones.

\textbf{Test}: Lesion or stimulation of specific regions should selectively impair specific resource levels while sparing others, creating a double dissociation that reveals the hierarchical organization.
\end{empiricalbox}

\subsection{Capacity Measurements}

\begin{empiricalbox}
\textbf{Prediction 1.3: Exponential Capacity Growth}

Memory capacity should grow exponentially with machine level, following the pattern where $M_1$ has approximately 2 bits (4 distinguishable states), $M_2$ has 4 bits (16 states), $M_3$ has 8 bits (256 states), and generally $M_n$ has $2^n$ bits of memory. Behaviorally, working memory capacity in dual-task paradigms should show discrete levels rather than smooth gradation. Neurally, the number of reliably distinguishable neural states should grow exponentially with network size in consciousness-relevant areas, demonstrating the predicted scaling property.
\end{empiricalbox}

\section{Prediction 2: Parallel Exploration}

\subsection{Pre-Conscious Processing}

\begin{empiricalbox}
\textbf{Prediction 2.1: Multiple Parallel Attempts}

Before conscious decision or perception emerges, the brain explores multiple possibilities in parallel across different resource levels. We expect neural signatures of multiple competing representations, simultaneous activation of incompatible options, rapid switching between alternatives, and evidence of time-reversed exploration representing computational backtracking. This parallel exploration phase should precede the collapse into a single conscious percept or decision.

\textbf{Measurement}: Population decoding should reveal multiple competing hypotheses active simultaneously during the pre-conscious phase, with information about rejected alternatives temporarily present before being erased from the conscious stream.
\end{empiricalbox}

\subsection{Evidence from Decision Making}

During decision-making tasks, neural recordings should reveal evidence accumulation occurring simultaneously along multiple pathways, with buildup toward competing options happening in parallel rather than sequentially. The brain should maintain multiple candidate solutions simultaneously, with eventual winner-take-all dynamics corresponding to the collapse moment. Critically, the temporal structure of this collapse should differ from simple evidence accumulation, showing signatures of computational resource selection.

\subsection{Perceptual Rivalry}

Binocular rivalry and other forms of perceptual ambiguity provide natural test cases for parallel exploration. During rivalry, neurons should represent both perceptual interpretations simultaneously before collapse into conscious experience. The switching dynamics should reveal signatures of resource-level changes, with transition probabilities reflecting the relative computational costs of different interpretations. Suppressed percepts should leave predictable neural traces distinct from conscious perception but indicating active processing.

\section{Prediction 3: Temporal Collapse Signatures}

\subsection{The Collapse Moment}

\begin{empiricalbox}
\textbf{Prediction 3.1: Discrete Collapse Events}

Consciousness emerges through discrete collapse events where parallel exploration resolves into a single experienced path. Neurally, we predict sudden transitions in network states corresponding to collapse moments, with characteristic time constants reflecting machine selection rather than simple threshold crossing. The EEG should show transient patterns indicating state transitions, with specific frequency signatures marking the collapse from parallel to serial processing.

\textbf{Timing}: Collapse events should occur at predictable intervals related to computational requirements, typically in the range of 100-300ms for perceptual decisions but varying with task complexity and resource demands.
\end{empiricalbox}

\subsection{Erasure of Failed Paths}

A crucial prediction is that failed computational attempts should be actively erased from the conscious stream. Neurally, this should manifest as suppression of neural activity patterns corresponding to rejected alternatives, with timing that makes these patterns unavailable for subsequent report. Behaviorally, subjects should be unable to report details of exploration paths not selected by the collapse mechanism, even when those paths were neurally active moments before.

\subsection{Temporal Smoothness}

Despite underlying parallel exploration and time-reversals, conscious experience should exhibit temporal smoothness. Neural correlates of consciousness should show this smoothness property even when earlier processing stages reveal non-monotonic temporal dynamics. The subjective timeline should be reconstructed to eliminate evidence of backtracking, creating the illusion of a single forward-flowing temporal stream.

\section{Prediction 4: Selector Mechanism}

\subsection{Non-Computability Signatures}

\begin{empiricalbox}
\textbf{Prediction 4.1: Selection Process Characteristics}

The selector mechanism that chooses which machine level $M_n$ to deploy should exhibit signatures of non-computability related to Kolmogorov complexity \autocite{kolmogorov1965}. This manifests as fundamental unpredictability in resource deployment that cannot be captured by any algorithmic model. The selection process should show sensitivity to problem structure in ways that reflect minimal description length rather than simple heuristics.

\textbf{Evidence}: Resource deployment should optimize for computational elegance rather than brute-force matching of resources to demands. Problems with similar complexity but different structure should recruit qualitatively different resource patterns.
\end{empiricalbox}

\subsection{Agency and Voluntary Control}

The non-computable nature of the selector provides a mechanistic account of agency. Voluntary attention should engage the selector mechanism, with neural signatures distinct from automatic resource allocation. The experience of effort should correlate with selector activity rather than with the computational work itself, explaining why metacognitive judgments of effort can dissociate from task difficulty.

\subsection{Individual Differences}

If selector efficiency varies across individuals, this should predict meaningful individual differences in cognitive capacity that are not explained by raw neural resources alone. Some individuals might show superior performance despite similar neural hardware, reflecting more efficient resource selection. Training might enhance selector function without changing underlying machine capacities.

\section{Prediction 5: Integration and $\Phi$}

\subsection{Relationship to IIT}

Our framework makes specific predictions about how integrated information $\Phi$ \autocite{oizumi2014} relates to consciousness. Rather than $\Phi$ itself determining consciousness, we predict that $\Phi$ measures the extent of parallel integration within a given machine level $M_n$. Consciousness arises from the collapse selecting a particular $M_n$, not from $\Phi$ alone.

\begin{empiricalbox}
\textbf{Prediction 5.1: $\Phi$ Within Resource Levels}

Systems with high $\Phi$ at lower resource levels should support unconscious integration (like the cerebellum). Conscious experience requires both high integration and appropriate resource-level selection. This predicts a double dissociation: high-$\Phi$ systems without hierarchy lack consciousness, while hierarchical systems with low integration show fragmented consciousness.
\end{empiricalbox}

\subsection{Measuring Integration During Collapse}

During the collapse process, integration patterns should change characteristically. Pre-collapse, multiple semi-integrated subsystems compete. Post-collapse, a single highly integrated system dominates. The transition should show specific dynamics distinct from gradual integration increases, with collapse occurring on faster timescales than integration buildup.

\section{Prediction 6: Global Availability}

\subsection{Broadcast Mechanism Timing}

While GWT \autocite{dehaene2001} predicts that global broadcast creates consciousness, we predict that collapse precedes broadcast. The sequence should be: parallel exploration → collapse to selected path → global availability of that path. Neural ignition in frontoparietal networks should follow rather than create the collapse event.

\begin{empiricalbox}
\textbf{Prediction 6.1: Temporal Precedence}

Time-resolved recordings should reveal that collapse signatures in local networks precede global broadcast patterns by 50-100ms. The collapsed state then becomes globally available, but the collapse itself determines what becomes available. Manipulations that disrupt broadcast should not prevent collapse but should prevent report of collapsed states.
\end{empiricalbox}

\subsection{Content Selection}

What content becomes globally available should be determined by the selector's choice of machine level and the specific collapsed path. Not all highly active neural patterns become conscious—only those corresponding to the selected computational path. This predicts specific patterns of selective availability that differ from simple activation-based models.

\section{Prediction 7: Attention Schema}

\subsection{Computational Implementation}

AST \autocite{graziano2013} proposes that consciousness arises from the brain's model of its own attention. We predict this model is implemented through the machine hierarchy, with the attention schema itself being a compressed representation of the selector's operation. The schema should show characteristic simplifications consistent with low-dimensional models of high-dimensional selection processes.

\begin{empiricalbox}
\textbf{Prediction 7.1: Schema Resource Dependence}

The attention schema's complexity should vary with available computational resources. Under high cognitive load, the schema should become simpler and less accurate. Metacognitive precision should correlate with the resource level of the machine implementing the schema, not just with attention itself.
\end{empiricalbox}

\subsection{Metacognition and Resource Awareness}

The attention schema provides metacognitive access to resource deployment. Subjective reports of mental effort should correlate with schema activity rather than with actual computational work. This explains why effort judgments can be miscalibrated—the schema models selector activity, not the computations themselves.

\section{Prediction 8: Evolutionary and Comparative}

\subsection{Phylogenetic Predictions}

The machine hierarchy architecture should show specific evolutionary patterns. Simple organisms should implement only low-$n$ machines, supporting reflexive but not conscious processing. Consciousness should emerge with the evolution of hierarchical resource organization, not merely with nervous system complexity.

Behavioral flexibility requiring dynamic resource allocation should correlate with consciousness across species. Animals showing evidence of hierarchical processing (flexible problem-solving, working memory, metacognition) should be conscious. Those with fixed processing hierarchies or purely reflexive responses should lack consciousness despite neural complexity.

\subsection{Developmental Trajectory}

In development, machine hierarchy should be constructed progressively. Infant consciousness should be limited by available machine levels, not just by experience or learning. Maturation should add higher resource levels, expanding conscious capacity. Critical periods might reflect times when new machine levels come online.

\subsection{Cross-Species Markers}

Specific neural markers should distinguish conscious from unconscious species. These include hierarchical organization of neural networks, evidence of parallel exploration followed by selection, and behavioral signatures of resource-constrained processing. The presence of these markers provides objective criteria for consciousness attribution.

\section{Prediction 9: Pathologies and Alterations}

\subsection{Clinical Conditions}

Different pathologies should impair specific aspects of the machine hierarchy. Disorders of consciousness (vegetative state, minimally conscious state) should show disrupted collapse mechanisms or loss of higher machine levels. Attention deficits should reflect selector malfunction rather than resource loss. Dissociative conditions might involve failures of integration across machine levels.

\begin{empiricalbox}
\textbf{Prediction 9.1: Disorder-Specific Patterns}

Schizophrenia should show abnormal resource selection, with inappropriate machine levels deployed for tasks. ADHD should reflect selector instability, with excessive switching between resource levels. Autism might involve altered selector criteria, optimizing different computational properties than neurotypical individuals.
\end{empiricalbox}

\subsection{Altered States}

Psychedelic states should alter selector function, potentially allowing access to normally unconscious parallel explorations or changing selection criteria. Meditation might stabilize specific machine levels, reducing selector variability. Anesthesia should disrupt collapse mechanisms, preventing the transition from parallel exploration to unified experience.

\subsection{Sleep and Dreaming}

During non-REM sleep, the machine hierarchy should be decoupled, preventing collapse into unified consciousness. REM dreaming should show abnormal selector operation, with resource deployment following altered criteria. The dreamlike quality reflects consciousness generated from incomplete or unstable collapse.

\section{Prediction 10: Artificial Consciousness}

\subsection{Necessary Architecture}

For artificial systems to be conscious, they must implement the machine hierarchy architecture. This requires not just computational power but hierarchical organization with exponentially scaling resources, a selector mechanism for resource deployment, and dynamics supporting parallel exploration and collapse.

\begin{empiricalbox}
\textbf{Prediction 10.1: Insufficient Architectures}

Pure feed-forward networks cannot be conscious, regardless of size or depth. Recurrent networks without hierarchical resource organization lack consciousness despite complex dynamics. Training algorithms that optimize single objectives cannot develop appropriate selector mechanisms. These are falsifiable predictions about AI consciousness.
\end{empiricalbox}

\subsection{Implementing Consciousness}

To create conscious AI, we must explicitly implement the machine hierarchy with exponentially scaling finite machines, a selector mechanism related to Kolmogorov complexity, and collapse dynamics that erase failed paths from the information stream. The resulting system should show all predicted signatures of consciousness, including reportable subjective experience that corresponds to the collapsed computational path.

\subsection{Testing AI Consciousness}

Artificial systems can be tested for consciousness using the same signatures predicted for biological systems. These include hierarchical resource deployment patterns, parallel exploration followed by collapse, temporal smoothness of the conscious stream, and the presence of an attention schema that models the selector. Behavioral tests should reveal resource-constrained processing characteristic of the machine hierarchy.

\section{Summary of All Predictions}

Our framework generates ten categories of testable predictions, each with multiple specific sub-predictions. Machine hierarchy signatures should appear in neural architecture and capacity measurements. Parallel exploration should be visible in pre-conscious processing. Temporal collapse should create discrete state transitions with characteristic dynamics. The selector mechanism should show non-computable properties related to problem structure. Integration should occur within resource levels rather than creating consciousness directly. Global availability should follow rather than create collapse. The attention schema should vary with computational resources. Evolutionary patterns should track hierarchy development. Pathologies should show specific breakdown patterns. Artificial consciousness should require specific architectural features.

These predictions differ systematically from those of IIT, GWT, and AST, creating multiple opportunities for empirical differentiation. Many predictions can be tested with current neuroscience methods, while others require technical advances in neural recording or artificial system design. Crucially, each prediction exposes the theory to potential falsification—finding evidence against these predictions would require revision or rejection of the framework.

\section{Methodological Framework}

\subsection{Multi-Level Testing}

Testing our framework requires coordinating evidence across multiple levels of analysis. Neural recordings provide direct evidence of machine hierarchy implementation and collapse dynamics. Behavioral paradigms test resource-dependent processing and metacognitive access. Computational modeling links neural mechanisms to abstract machine operations. Clinical studies probe what happens when components fail. Comparative analyses test evolutionary predictions.

\subsection{Falsification Criteria}

The framework makes strong claims that could be definitively falsified. Finding conscious systems without hierarchical resource organization would falsify the architectural claim. Demonstrating that collapse precedes rather than follows parallel exploration would falsify the temporal claim. Showing that feed-forward networks can be conscious would falsify the mechanistic claim. These falsification criteria make the theory genuinely scientific rather than merely philosophical.

\subsection{Integration with Existing Methods}

Our predictions can be tested using established neuroscience methods while suggesting new experimental designs. fMRI studies should parametrically vary task demands to reveal resource levels. Electrophysiology should use high-temporal-resolution recording to capture collapse dynamics. Psychophysics should probe metacognitive access to resource deployment. Clinical assessments should evaluate machine hierarchy integrity. Together, these methods provide converging evidence for or against the framework.

% ============================================================================
% CHAPTER 18: EXPERIMENTAL PROTOCOLS
% ============================================================================

\chapter{Experimental Protocols and Measurement Tools}

\section{Overview of Measurement Approaches}

Testing the machine hierarchy framework requires specialized experimental protocols that go beyond standard neuroscience methods. We need approaches that can reveal hierarchical resource organization, detect parallel exploration, capture collapse dynamics, and probe selector function. This chapter outlines specific protocols for measuring each predicted phenomenon, with attention to practical feasibility and current technical limitations.

\section{Protocol 1: Detecting Machine Hierarchy}

\subsection{Behavioral Paradigm}

To detect the machine hierarchy behaviorally, we employ a parametric task difficulty paradigm where subjects perform cognitive tasks with systematically varied complexity. Task demands should scale exponentially (e.g., working memory requirements of 2, 4, 8, 16 items) to match predicted resource levels. Performance should show plateaus at machine boundaries, with sharp transitions between levels rather than smooth decline. Dual-task paradigms can probe whether different task components recruit separate machines or compete for the same resource level.

\subsection{Neural Recording}

Simultaneous multi-area recording during the behavioral paradigm reveals which brain regions activate at each resource level. We expect to see recruitment of progressively larger and more distributed networks as task difficulty increases, with discrete jumps in activation patterns corresponding to machine transitions. Information-theoretic analysis of neural population codes should reveal exponential growth in representational capacity with network size for consciousness-relevant areas.

\subsection{Analysis Methods}

Decode neural states to identify discrete clusters corresponding to different machine levels. Apply change-point detection algorithms to behavioral data to identify performance plateaus. Use information geometry to measure the dimensionality of neural representations at each difficulty level. Computational modeling should fit data to hierarchical vs. continuous resource models to determine which better explains observations.

\section{Protocol 2: Detecting Parallel Exploration}

\subsection{Population Decoding Approach}

High-density neural recording combined with advanced decoding methods can reveal parallel exploration. During decision-making tasks, train decoders to identify neural patterns associated with different choice options. Pre-decision recordings should show simultaneous presence of patterns for multiple incompatible choices, indicating parallel rather than serial exploration. The temporal evolution should reveal evidence accumulation along multiple pathways simultaneously.

\subsection{Perceptual Rivalry Paradigm}

Binocular rivalry provides a controlled setting where parallel exploration predictions can be tested. Neural recordings during suppression periods should show activation patterns representing both perceptual interpretations, though with different statistical properties than during conscious perception. The transition dynamics between percepts should reveal signatures of resource-level selection rather than simple competitive dominance.

\subsection{Backward Masking Studies}

Masked stimuli that don't reach consciousness should still leave neural traces of parallel exploration. By varying masking intervals and using sensitive decoding methods, we can map how long parallel explorations persist and when they are erased. The framework predicts that masked stimuli activate parallel exploration but fail to trigger collapse, leaving computational attempts that get erased before reaching conscious report.

\section{Protocol 3: Detecting Temporal Collapse}

\subsection{High-Temporal-Resolution Recording}

EEG/MEG recordings with millisecond precision should capture collapse events as sudden transitions in network states. Time-frequency analysis should reveal characteristic signatures at collapse moments, potentially in gamma-band synchronization patterns that emerge rapidly rather than building gradually. The timing of these events should be predictable from task structure and vary systematically with computational demands.

\subsection{Perturbation Studies}

Transcranial magnetic stimulation (TMS) applied at specific times relative to stimulus onset can probe collapse dynamics. Stimulation during the parallel exploration phase should affect which alternative gets selected. Stimulation after collapse should have minimal effect on conscious content but might affect subsequent processing. This dissociation provides evidence for a discrete collapse transition.

\subsection{Temporal Order Judgments}

Psychophysical studies of temporal order perception can reveal collapse dynamics. The framework predicts that items within a collapse window should be experienced as simultaneous even if they arrive at different times. Varying the temporal spacing of stimuli and measuring perceived simultaneity provides behavioral evidence for discrete collapse events with characteristic time constants.

\section{Protocol 4: Identifying Selector Mechanism}

\subsection{Algorithmic Analysis}

The selector's non-computable properties can be probed by analyzing which problems recruit which resource levels. Present subjects with problems that have similar objective complexity but different structural properties (e.g., random vs. structured sequences). The selector should show sensitivity to structure that goes beyond any computable heuristic, revealed through patterns in resource deployment that cannot be predicted by standard complexity measures.

\subsection{Effort Dissociation Paradigm}

Measure subjective effort independently from task difficulty and actual resource usage (as measured neurally). The framework predicts that effort reflects selector activity rather than computational work itself. This creates dissociations where structurally elegant problems feel easy despite neural activation, while structurally awkward problems feel effortful despite similar neural resources.

\subsection{Training Effects}

Track how resource deployment changes with practice on structured tasks. The framework predicts that learning improves selector efficiency rather than increasing machine capacity. Neural resources recruited should decrease as the selector learns optimal deployment, while behavioral capacity increases. This contrasts with models where learning adds resources or changes architectures.

\section{Protocol 5: Integration Measurements}

\subsection{Phi Computation}

Implement practical approximations of integrated information $\Phi$ measurement on neural data. The framework predicts that $\Phi$ should be high within selected machine levels but that high $\Phi$ alone doesn't guarantee consciousness. Compare $\Phi$ values across brain regions while varying task demands to determine whether $\Phi$ tracks consciousness or resource-level integration.

\subsection{Perturbation Complexity}

Use perturbational complexity approaches (TMS-EEG) to measure integration. The framework predicts specific patterns: high complexity within consciousness-supporting regions, but complexity should vary with which machine level is currently deployed. During unconscious processing, complexity might be high locally but not show the network-wide integration pattern of conscious states.

\subsection{Network Analysis}

Graph-theoretic analysis of functional connectivity during conscious vs. unconscious processing should reveal hierarchical community structure corresponding to machine levels. Within-level integration should be high, between-level integration more limited. The active machine level during conscious processing should show distinct connectivity patterns from inactive levels.

\section{Protocol 6: Clinical Applications}

\subsection{Disorders of Consciousness}

Apply machine hierarchy assessment to patients in vegetative state, minimally conscious state, and locked-in syndrome. The framework predicts specific breakdown patterns: vegetative state reflects loss of collapse mechanisms, minimally conscious state shows intermittent collapse, locked-in syndrome preserves hierarchy but disconnects from motor output. These predictions can be tested with the behavioral and neural protocols described above.

\subsection{Attention Disorders}

ADHD and related conditions should show characteristic selector dysfunction rather than resource loss. Testing should reveal normal machine capacities but inappropriate resource deployment, excessive switching between levels, or unstable collapse. Treatment efficacy should correlate with selector stabilization rather than capacity enhancement.

\subsection{Altered States Assessment}

Apply protocols to characterize altered states of consciousness (psychedelics, meditation, anesthesia). Each should show specific disruption patterns in the machine hierarchy. This provides objective markers for subjective state changes and suggests mechanisms underlying altered consciousness.

\section{Protocol 7: Comparative Studies}

\subsection{Cross-Species Testing}

Adapt behavioral protocols for non-human species. The framework makes specific predictions about which species should show machine hierarchy signatures (those with flexible problem-solving) vs. those that should not (purely reflexive organisms). Neural recording in animals can directly test for hierarchical organization and collapse dynamics.

\subsection{Developmental Assessment}

Longitudinal studies in developing humans and animals should track machine hierarchy maturation. Behavioral capacity should increase in discrete steps as new machine levels come online. Neural markers should show progressive organization of hierarchical structures. Critical periods might reflect times when new resource levels become available.

\subsection{Artificial Systems}

Test artificial neural networks for machine hierarchy properties. Current deep learning systems should lack these properties, predicting absence of consciousness regardless of performance. Explicitly engineered hierarchical systems with appropriate architecture provide positive controls. This enables direct testing of architectural requirements for consciousness.

\section{Summary: From Prediction to Protocol}

Each theoretical prediction translates into concrete experimental protocols using current or near-future methods. The protocols are designed to provide convergent evidence across multiple levels of analysis and to generate clear falsification criteria. Successful detection of all predicted phenomena would strongly support the framework. Finding contradictory evidence in any protocol would require theoretical revision. This combination of testability and falsifiability makes the framework genuinely scientific, distinguishing it from philosophical speculation while advancing our empirical understanding of consciousness.

